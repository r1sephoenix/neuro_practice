{
 "cells": [
  {
   "metadata": {
    "collapsed": false
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import mne\n",
    "from mne.beamformer import apply_lcmv, make_lcmv\n",
    "from mne.datasets import fetch_fsaverage, sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to beamformers\n",
    "A beamformer is a spatial filter that reconstructs source activity by\n",
    "scanning through a grid of pre-defined source points and estimating activity\n",
    "at each of those source points independently. A set of weights is\n",
    "constructed for each defined source location which defines the contribution\n",
    "of each sensor to this source.\n",
    "\n",
    "Beamformers are often used for their focal reconstructions and their ability\n",
    "to reconstruct deeper sources. They can also suppress external noise sources.\n",
    "The beamforming method applied in this tutorial is the linearly constrained\n",
    "minimum variance (LCMV) beamformer :footcite:`VanVeenEtAl1997` operates on\n",
    "time series.\n",
    "\n",
    "Frequency-resolved data can be reconstructed with the dynamic imaging of\n",
    "coherent sources (DICS) beamforming method :footcite:`GrossEtAl2001`.\n",
    "As we will see in the following, the spatial filter is computed from two\n",
    "ingredients: the forward model solution and the covariance matrix of the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing\nWe will use the sample data set for this tutorial and reconstruct source\nactivity on the trials with left auditory stimulation.\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_path = sample.data_path()\nsubjects_dir = data_path / \"subjects\"\nmeg_path = data_path / \"MEG\" / \"sample\"\nraw_fname = meg_path / \"sample_audvis_filt-0-40_raw.fif\"\n\n# Read the raw data\nraw = mne.io.read_raw_fif(raw_fname)\nraw.info[\"bads\"] = [\"MEG 2443\"]  # bad MEG channel\n\n# Set up epoching\nevent_id = 1  # those are the trials with left-ear auditory stimuli\ntmin, tmax = -0.2, 0.5\nevents = mne.find_events(raw)\n\n# pick relevant channels\nraw.pick([\"meg\", \"eog\"])  # pick channels of interest\n\n# Create epochs\nproj = False  # already applied\nepochs = mne.Epochs(\n    raw,\n    events,\n    event_id,\n    tmin,\n    tmax,\n    baseline=(None, 0),\n    preload=True,\n    proj=proj,\n    reject=dict(grad=4000e-13, mag=4e-12, eog=150e-6),\n)\n\n# for speed purposes, cut to a window of interest\nevoked = epochs.average().crop(0.05, 0.15)\n\n# Visualize averaged sensor space data\nevoked.plot_joint()\n\ndel raw  # save memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_cov = mne.compute_covariance(epochs, tmin=0.01, tmax=0.25, method=\"empirical\")\nnoise_cov = mne.compute_covariance(epochs, tmin=tmin, tmax=0, method=\"empirical\")\ndata_cov.plot(epochs.info)\ndel epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When looking at the covariance matrix plots, we can see that our data is\n",
    "slightly rank-deficient as the rank is not equal to the number of channels.\n",
    "Thus, we choose to regularize the covariance matrix before inverting it\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The forward model\n",
    "The forward model is the other important ingredient for the computation of a\n",
    "spatial filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fwd_fname = meg_path / \"sample_audvis-meg-vol-7-fwd.fif\"\n",
    "forward = mne.read_forward_solution(fwd_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling depth bias\n",
    "\n",
    "The forward model solution is inherently biased toward superficial sources.\n",
    "When analyzing single conditions it is best to mitigate the depth bias\n",
    "somehow. There are several ways to do this:\n",
    "\n",
    "\n",
    "## Compute the spatial filter\n",
    "Now we can compute the spatial filter. We'll use a unit-noise gain beamformer\n",
    "to deal with depth bias, and will also optimize the orientation of the\n",
    "sources such that output power is maximized.\n",
    "This is achieved by setting ``pick_ori='max-power'``.\n",
    "This gives us one source estimate per source (i.e., voxel), which is known\n",
    "as a scalar beamformer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filters = make_lcmv(\n    evoked.info,\n    forward,\n    data_cov,\n    reg=0.05,\n    noise_cov=noise_cov,\n    pick_ori=\"max-power\",\n    weight_norm=\"unit-noise-gain\",\n    rank=None,\n)\n\n# You can save the filter for later use with:\n# filters.save('filters-lcmv.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filters_vec = make_lcmv(\n    evoked.info,\n    forward,\n    data_cov,\n    reg=0.05,\n    noise_cov=noise_cov,\n    pick_ori=\"vector\",\n    weight_norm=\"unit-noise-gain-invariant\",\n    rank=None,\n)\n# save a bit of memory\nsrc = forward[\"src\"]\ndel forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stc = apply_lcmv(evoked, filters)\nstc_vec = apply_lcmv(evoked, filters_vec)\ndel filters, filters_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the reconstructed source activity\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lims = [0.3, 0.45, 0.6]\nkwargs = dict(\n    src=src,\n    subject=\"sample\",\n    subjects_dir=subjects_dir,\n    initial_time=0.087,\n    verbose=True,\n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On MRI slices (orthoview; 2D)\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stc.plot(mode=\"stat_map\", clim=dict(kind=\"value\", pos_lims=lims), **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On MNI glass brain (orthoview; 2D)\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stc.plot(mode=\"glass_brain\", clim=dict(kind=\"value\", lims=lims), **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volumetric rendering (3D) with vectors\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "brain = stc_vec.plot_3d(\n    clim=dict(kind=\"value\", lims=lims),\n    hemi=\"both\",\n    size=(600, 600),\n    views=[\"sagittal\"],\n    # Could do this for a 3-panel figure:\n    # view_layout='horizontal', views=['coronal', 'sagittal', 'axial'],\n    brain_kwargs=dict(silhouette=True),\n    **kwargs,\n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the activity of the maximum voxel with all three components\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "peak_vox, _ = stc_vec.get_peak(tmin=0.08, tmax=0.1, vert_as_index=True)\n\nori_labels = [\"x\", \"y\", \"z\"]\nfig, ax = plt.subplots(1)\nfor ori, label in zip(stc_vec.data[peak_vox, :, :], ori_labels):\n    ax.plot(stc_vec.times, ori, label=f\"{label} component\")\nax.legend(loc=\"lower right\")\nax.set(\n    title=\"Activity per orientation in the peak voxel\",\n    xlabel=\"Time (s)\",\n    ylabel=\"Amplitude (a. u.)\",\n)\nmne.viz.utils.plt_show()\ndel stc_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Morph the output to fsaverage\n",
    "\n",
    "We can also use volumetric morphing to get the data to fsaverage space\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fetch_fsaverage(subjects_dir)  # ensure fsaverage src exists\nfname_fs_src = subjects_dir / \"fsaverage\" / \"bem\" / \"fsaverage-vol-5-src.fif\"\n\nsrc_fs = mne.read_source_spaces(fname_fs_src)\nmorph = mne.compute_source_morph(\n    src,\n    subject_from=\"sample\",\n    src_to=src_fs,\n    subjects_dir=subjects_dir,\n    niter_sdr=[5, 5, 2],\n    niter_affine=[5, 5, 2],\n    zooms=7,  # just for speed\n    verbose=True,\n)\nstc_fs = morph.apply(stc)\ndel stc\n\nstc_fs.plot(\n    src=src_fs,\n    mode=\"stat_map\",\n    initial_time=0.085,\n    subjects_dir=subjects_dir,\n    clim=dict(kind=\"value\", pos_lims=lims),\n    verbose=True,\n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
