{
 "cells": [
  {
   "cell_type": "raw",
   "id": "a82cd00865b9e397",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c00c4e1b68e15004",
   "metadata": {},
   "source": [
    "# BCI Classification Pipeline - Complete Walkthrough\n",
    "\n",
    "## Brain-Computer Interface Classification using MNE Python\n",
    "\n",
    "This notebook demonstrates a complete BCI classification pipeline using EEG motor imagery data from PhysioNet.\n",
    "\n",
    "### Pipeline Steps:\n",
    "1. **Data Loading** - Load EEG Motor Movement/Imagery Dataset\n",
    "2. **Data Exploration** - Visualize raw data and events\n",
    "3. **Preprocessing** - Filtering, artifact removal, epoching\n",
    "4. **Feature Extraction** - CSP, PSD, time-domain features\n",
    "5. **Classification** - Train and evaluate multiple algorithms\n",
    "6. **Results Analysis** - Performance comparison and visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e590b2fdd88bbdc",
   "metadata": {},
   "source": [
    "##  Setup and Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14c5f61d39a7df9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T07:10:36.613338Z",
     "start_time": "2025-11-08T07:10:36.610043Z"
    }
   },
   "outputs": [],
   "source": [
    "# import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "import mne\n",
    "from mne.datasets import eegbci\n",
    "\n",
    "# Our BCI classifier package\n",
    "from bci_classifier import (\n",
    "    DataLoader, \n",
    "    Preprocessor, \n",
    "    FeatureExtractor, \n",
    "    BCIClassifier,\n",
    "    BCIPipeline\n",
    ")\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "# %matplotlib inline\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "mne.set_log_level('WARNING')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468e33dc987376fd",
   "metadata": {},
   "source": [
    "##  Data Loading\n",
    "\n",
    "Let's start by loading the EEG Motor Movement/Imagery Dataset from PhysioNet. This dataset contains EEG recordings from 109 volunteers performing motor/imagery tasks.\n",
    "\n",
    "### Dataset Information:\n",
    "- **Subjects**: 109 volunteers\n",
    "- **Tasks**: Left/right hand motor imagery, fist opening/closing\n",
    "- **Channels**: 64 EEG channels\n",
    "- **Sampling Rate**: 160 Hz\n",
    "- **Runs**: Different motor tasks (we'll use runs 6, 10, 14 for motor imagery)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bf0095a12c1d6531",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T07:10:57.765766Z",
     "start_time": "2025-11-08T07:10:57.563807Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading EEG data for Subject 1\n",
      " Using runs: [4, 8, 12] (motor imagery tasks)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Missing channels from ch_names required by include:\n['STI 014']",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m Using runs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mRUNS\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (motor imagery tasks)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Load data\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m raw, events, event_id = \u001b[43mloader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_eegbci_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject\u001b[49m\u001b[43m=\u001b[49m\u001b[43mSUBJECT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mRUNS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Get data information\u001b[39;00m\n\u001b[32m     15\u001b[39m info = loader.get_info()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/neuro_practice/bci_classifier/data_loader.py:104\u001b[39m, in \u001b[36mDataLoader.load_eegbci_data\u001b[39m\u001b[34m(self, subject, runs)\u001b[39m\n\u001b[32m    101\u001b[39m \u001b[38;5;28mself\u001b[39m.raw.set_montage(montage, verbose=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    103\u001b[39m \u001b[38;5;66;03m# Find events\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m \u001b[38;5;28mself\u001b[39m.events = \u001b[43mmne\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfind_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshortest_event\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstim_channel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mSTI 014\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[38;5;66;03m# Event IDs for motor imagery\u001b[39;00m\n\u001b[32m    107\u001b[39m \u001b[38;5;28mself\u001b[39m.event_id = {\n\u001b[32m    108\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mleft_hand\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m2\u001b[39m,\n\u001b[32m    109\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mright_hand\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m3\u001b[39m,\n\u001b[32m    110\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mrest\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m1\u001b[39m\n\u001b[32m    111\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<decorator-gen-143>:10\u001b[39m, in \u001b[36mfind_events\u001b[39m\u001b[34m(raw, stim_channel, output, consecutive, min_duration, shortest_event, mask, uint_cast, mask_type, initial_event, verbose)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/bci-classifier-vAvhJyZy-py3.13/lib/python3.13/site-packages/mne/event.py:767\u001b[39m, in \u001b[36mfind_events\u001b[39m\u001b[34m(raw, stim_channel, output, consecutive, min_duration, shortest_event, mask, uint_cast, mask_type, initial_event, verbose)\u001b[39m\n\u001b[32m    764\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    765\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m767\u001b[39m picks = \u001b[43mpick_channels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw\u001b[49m\u001b[43m.\u001b[49m\u001b[43minfo\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mch_names\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstim_channel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    768\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(picks) == \u001b[32m0\u001b[39m:\n\u001b[32m    769\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo stim channel found to extract event triggers.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<decorator-gen-7>:12\u001b[39m, in \u001b[36mpick_channels\u001b[39m\u001b[34m(ch_names, include, exclude, ordered, verbose)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/bci-classifier-vAvhJyZy-py3.13/lib/python3.13/site-packages/mne/_fiff/pick.py:306\u001b[39m, in \u001b[36mpick_channels\u001b[39m\u001b[34m(ch_names, include, exclude, ordered, verbose)\u001b[39m\n\u001b[32m    304\u001b[39m         missing.append(name)\n\u001b[32m    305\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing) \u001b[38;5;129;01mand\u001b[39;00m ordered:\n\u001b[32m--> \u001b[39m\u001b[32m306\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    307\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing channels from ch_names required by include:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmissing\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    308\u001b[39m     )\n\u001b[32m    309\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ordered:\n\u001b[32m    310\u001b[39m     sel = np.unique(sel)\n",
      "\u001b[31mValueError\u001b[39m: Missing channels from ch_names required by include:\n['STI 014']"
     ]
    }
   ],
   "source": [
    "# Initialize data loader\n",
    "loader = DataLoader()\n",
    "\n",
    "# Configuration\n",
    "SUBJECT = 1\n",
    "RUNS = [4, 8, 12]  # Alternate motor imagery runs for hands and feet\n",
    "\n",
    "print(f\"Loading EEG data for Subject {SUBJECT}\")\n",
    "print(f\" Using runs: {RUNS} (motor imagery tasks)\")\n",
    "\n",
    "# Load data\n",
    "raw, events, event_id = loader.load_eegbci_data(subject=SUBJECT, runs=RUNS)\n",
    "\n",
    "# Get data information\n",
    "info = loader.get_info()\n",
    "print(\"\\nDataset Information:\")\n",
    "print(f\"   Channels: {info['n_channels']}\")\n",
    "print(f\"   Sampling Rate: {info['sampling_rate']} Hz\")\n",
    "print(f\"   Duration: {info['duration']:.1f} seconds\")\n",
    "print(f\"   Events: {info['n_events']}\")\n",
    "print(f\"   Event Types: {info['event_types']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6baea7acf2c824ce",
   "metadata": {},
   "source": [
    "## 2. Data Exploration\n",
    "\n",
    "Let's explore the raw data and visualize the EEG signals and events.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d01a90badb8fb82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T06:59:04.220045Z",
     "start_time": "2025-11-08T06:59:04.202353Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Visualizing raw EEG data (first 10 seconds)...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'raw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Plot raw data (first 10 seconds)\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m Visualizing raw EEG data (first 10 seconds)...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m fig = \u001b[43mraw\u001b[49m.plot(duration=\u001b[32m10\u001b[39m, n_channels=\u001b[32m20\u001b[39m, scalings={\u001b[33m'\u001b[39m\u001b[33meeg\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m20e-6\u001b[39m}, \n\u001b[32m      4\u001b[39m                title=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRaw EEG Data - Subject \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSUBJECT\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m plt.tight_layout()\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Plot events\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'raw' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot raw data (first 10 seconds)\n",
    "print(\" Visualizing raw EEG data (first 10 seconds)...\")\n",
    "fig = raw.plot(duration=10, n_channels=20, scalings={'eeg': 20e-6}, \n",
    "               title=f\"Raw EEG Data - Subject {SUBJECT}\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# Plot events\n",
    "print(f\"\\n Event distribution:\")\n",
    "event_counts = {name: np.sum(events[:, -1] == id_) for name, id_ in event_id.items()}\n",
    "for event_name, count in event_counts.items():\n",
    "    print(f\"   {event_name}: {count} events\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6354ced561591d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize events on timeline\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 4))\n",
    "\n",
    "# Plot events\n",
    "for event_name, event_code in event_id.items():\n",
    "    event_times = events[events[:, -1] == event_code, 0] / raw.info['sfreq']\n",
    "    ax.scatter(event_times, [event_code] * len(event_times), \n",
    "               label=event_name, alpha=0.7, s=30)\n",
    "\n",
    "ax.set_xlabel('Time (seconds)')\n",
    "ax.set_ylabel('Event Code')\n",
    "ax.set_title('Event Timeline')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34333a21b43952",
   "metadata": {},
   "source": [
    "##  3. Data Preprocessing\n",
    "\n",
    "Now we'll preprocess the data including:\n",
    "- Creating epochs around events\n",
    "- Band-pass filtering (8-30 Hz for motor imagery)\n",
    "- Common Average Reference (CAR)\n",
    "- Artifact rejection\n",
    "- Optional ICA for artifact removal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93968e13f6f021dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create epochs\n",
    "print(\" Creating epochs around events...\")\n",
    "TMIN, TMAX = -1.0, 4.0  # 1 second before to 4 seconds after event\n",
    "BASELINE = (-1.0, 0.0)   # Baseline correction period\n",
    "\n",
    "epochs = loader.get_epochs(tmin=TMIN, tmax=TMAX, baseline=BASELINE)\n",
    "print(f\"Created {len(epochs)} epochs\")\n",
    "print(f\"Epoch shape: {epochs.get_data().shape}\")\n",
    "\n",
    "# Initialize preprocessor\n",
    "preprocessor = Preprocessor()\n",
    "\n",
    "# Apply preprocessing\n",
    "print(\"\\n Applying preprocessing steps...\")\n",
    "L_FREQ, H_FREQ = 8.0, 30.0  # Motor imagery frequency band\n",
    "\n",
    "epochs_processed = preprocessor.preprocess_epochs(\n",
    "    epochs,\n",
    "    l_freq=L_FREQ,\n",
    "    h_freq=H_FREQ,\n",
    "    apply_ica=False,  # Skip ICA for faster execution (set to True for better results)\n",
    "    apply_car=True,   # Apply Common Average Reference\n",
    "    reject_bad=True   # Reject bad epochs\n",
    ")\n",
    "\n",
    "print(f\"Preprocessing completed\")\n",
    "print(f\"Final epochs: {len(epochs_processed)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53b147c905e236e",
   "metadata": {},
   "source": [
    "## Preprocessed Data Visualization\n",
    "\n",
    "Let's visualize the preprocessed data to see the effect of filtering and preprocessing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316ba15ff4b016aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare raw vs preprocessed epochs\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\n",
    "# Plot average of raw epochs\n",
    "epochs_raw = epochs.copy().crop(tmin=0, tmax=3)  # Focus on event period\n",
    "raw_avg = epochs_raw.average()\n",
    "raw_avg.plot(axes=axes[0], show=False, titles={'eeg': 'Raw Data (Average)'})\n",
    "axes[0].set_title('Raw EEG (Average across trials)')\n",
    "\n",
    "# Plot average of processed epochs\n",
    "processed_avg = epochs_processed.copy().crop(tmin=0, tmax=3).average()\n",
    "processed_avg.plot(axes=axes[1], show=False, titles={'eeg': 'Processed Data (Average)'})\n",
    "axes[1].set_title('Preprocessed EEG (Average across trials)')\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4ddc8956bb523f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot power spectral density comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Raw data PSD\n",
    "epochs.plot_psd(fmin=1, fmax=50, ax=axes[0], show=False)\n",
    "axes[0].set_title('Raw Data - Power Spectral Density')\n",
    "\n",
    "# Processed data PSD\n",
    "epochs_processed.plot_psd(fmin=1, fmax=50, ax=axes[1], show=False)\n",
    "axes[1].set_title('Processed Data - Power Spectral Density')\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d3c7f98833522f",
   "metadata": {},
   "source": [
    "##  4. Feature Extraction\n",
    "\n",
    "We'll extract different types of features for classification:\n",
    "1. **Common Spatial Patterns (CSP)** - Best for motor imagery\n",
    "2. **Power Spectral Density (PSD)** - Frequency domain features\n",
    "3. **Time-domain features** - Statistical features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374fe78a6d59cfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train/test sets\n",
    "print(\"Splitting data into train/test sets...\")\n",
    "\n",
    "# Get labels from epochs\n",
    "labels = epochs_processed.events[:, -1]\n",
    "print(f\"Label distribution: {np.bincount(labels)}\")\n",
    "\n",
    "# Split epochs\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "n_epochs = len(epochs_processed)\n",
    "indices = np.arange(n_epochs)\n",
    "train_idx, test_idx = train_test_split(\n",
    "    indices, test_size=0.2, stratify=labels, random_state=42\n",
    ")\n",
    "\n",
    "epochs_train = epochs_processed[train_idx]\n",
    "epochs_test = epochs_processed[test_idx]\n",
    "y_train = epochs_train.events[:, -1]\n",
    "y_test = epochs_test.events[:, -1]\n",
    "\n",
    "print(f\"Training: {len(epochs_train)} epochs\")\n",
    "print(f\"Testing: {len(epochs_test)} epochs\")\n",
    "print(f\"Train labels: {np.bincount(y_train)}\")\n",
    "print(f\"Test labels: {np.bincount(y_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d594308e9c336e",
   "metadata": {},
   "source": [
    "### 4.1 Common Spatial Patterns (CSP) Features\n",
    "\n",
    "CSP finds spatial filters that maximize the variance ratio between different classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f784e77c14ce23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract CSP features\n",
    "print(\"üîß Extracting CSP features...\")\n",
    "\n",
    "csp_extractor = FeatureExtractor(method='csp', n_components=6)\n",
    "X_train_csp = csp_extractor.fit_transform(epochs_train, y_train)\n",
    "X_test_csp = csp_extractor.transform(epochs_test, y_test)\n",
    "\n",
    "print(f\" CSP features extracted!\")\n",
    "print(f\" Training features shape: {X_train_csp.shape}\")\n",
    "print(f\" Testing features shape: {X_test_csp.shape}\")\n",
    "\n",
    "# Visualize CSP patterns\n",
    "csp = csp_extractor.csp\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    mne.viz.plot_topomap(csp.patterns_[i], epochs_processed.info, axes=ax, show=False)\n",
    "    ax.set_title(f'CSP Pattern {i+1}')\n",
    "\n",
    "plt.suptitle('CSP Spatial Patterns')\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af69fcf976be442",
   "metadata": {},
   "source": [
    "### 4.2 Power Spectral Density (PSD) Features\n",
    "\n",
    "PSD features capture frequency-domain information in different EEG bands.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaed0b347494ab97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract PSD features\n",
    "print(\" Extracting PSD features...\")\n",
    "\n",
    "psd_extractor = FeatureExtractor(method='psd')\n",
    "X_train_psd = psd_extractor.fit_transform(epochs_train, y_train)\n",
    "X_test_psd = psd_extractor.transform(epochs_test)\n",
    "\n",
    "print(f\" PSD features extracted!\")\n",
    "print(f\"Training features shape: {X_train_psd.shape}\")\n",
    "print(f\" Testing features shape: {X_test_psd.shape}\")\n",
    "\n",
    "# Visualize average PSD features by class\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Create DataFrame for easier plotting\n",
    "feature_names = psd_extractor.get_feature_names()\n",
    "psd_df = pd.DataFrame(X_train_psd, columns=feature_names)\n",
    "psd_df['class'] = y_train\n",
    "\n",
    "# Plot average PSD by frequency band for first few channels\n",
    "bands = ['alpha', 'beta', 'gamma', 'theta']\n",
    "channels = ['C3', 'C4', 'Cz']  # Motor cortex channels\n",
    "\n",
    "plot_data = []\n",
    "for band in bands:\n",
    "    for channel in channels:\n",
    "        if any(f'{channel}_{band}' in col for col in feature_names):\n",
    "            col_name = next(col for col in feature_names if f'{channel}_{band}' in col)\n",
    "            for class_id in np.unique(y_train):\n",
    "                class_name = [k for k, v in event_id.items() if v == class_id][0]\n",
    "                mean_power = psd_df[psd_df['class'] == class_id][col_name].mean()\n",
    "                plot_data.append({'band': band, 'channel': channel, \n",
    "                                'class': class_name, 'power': mean_power})\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "sns.barplot(data=plot_df, x='band', y='power', hue='class')\n",
    "plt.title('Average PSD Features by Frequency Band and Class')\n",
    "plt.ylabel('Power')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5975390c6c5d329f",
   "metadata": {},
   "source": [
    "### 4.3 Time-Domain Features\n",
    "\n",
    "Statistical features extracted from the time series data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa9a270fd74ca32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract time-domain features\n",
    "print(\" Extracting time-domain features...\")\n",
    "\n",
    "time_extractor = FeatureExtractor(method='time_domain')\n",
    "X_train_time = time_extractor.fit_transform(epochs_train, y_train)\n",
    "X_test_time = time_extractor.transform(epochs_test)\n",
    "\n",
    "print(f\" Time-domain features extracted!\")\n",
    "print(f\" Training features shape: {X_train_time.shape}\")\n",
    "print(f\" Testing features shape: {X_test_time.shape}\")\n",
    "\n",
    "# Visualize time-domain features\n",
    "time_feature_names = time_extractor.get_feature_names()\n",
    "print(f\" Time-domain features (first 10): {time_feature_names[:10]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f782a6de7a445b",
   "metadata": {},
   "source": [
    "##  5. Classification\n",
    "\n",
    "Now we'll train and evaluate different classification algorithms on our features.\n",
    "\n",
    "### 5.1 CSP + SVM Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cdfac85381a0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train SVM classifier on CSP features\n",
    "print(\" Training SVM classifier on CSP features...\")\n",
    "\n",
    "svm_classifier = BCIClassifier(algorithm='svm', random_state=42)\n",
    "svm_classifier.fit(X_train_csp, y_train, normalize=True)\n",
    "\n",
    "# Evaluate on test set\n",
    "results_svm = svm_classifier.evaluate(X_test_csp, y_test, normalize=True)\n",
    "print(f\"SVM Test Accuracy: {results_svm['accuracy']:.3f}\")\n",
    "\n",
    "# Cross-validation on training set\n",
    "cv_results_svm = svm_classifier.cross_validate(X_train_csp, y_train, cv=5)\n",
    "print(f\" SVM CV Accuracy: {cv_results_svm['mean_accuracy']:.3f} ¬± {cv_results_svm['std_accuracy']:.3f}\")\n",
    "\n",
    "# Plot confusion matrix\n",
    "class_names = list(event_id.keys())\n",
    "svm_classifier.plot_confusion_matrix(\n",
    "    results_svm['confusion_matrix'], \n",
    "    class_names=class_names,\n",
    "    title='SVM Confusion Matrix (CSP Features)'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a774ce49b02966",
   "metadata": {},
   "source": [
    "### 5.2 Algorithm Comparison\n",
    "\n",
    "Let's compare multiple algorithms on CSP features:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3809576beb7169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare multiple algorithms\n",
    "print(\" Comparing multiple classification algorithms...\")\n",
    "\n",
    "algorithms = ['svm', 'lda', 'rf', 'lr']\n",
    "comparison_results = {}\n",
    "\n",
    "for alg in algorithms:\n",
    "    print(f\"Training {alg.upper()}...\")\n",
    "    classifier = BCIClassifier(algorithm=alg, random_state=42)\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_results = classifier.cross_validate(X_train_csp, y_train, cv=5)\n",
    "    \n",
    "    # Train and test\n",
    "    classifier.fit(X_train_csp, y_train)\n",
    "    test_results = classifier.evaluate(X_test_csp, y_test)\n",
    "    \n",
    "    comparison_results[alg] = {\n",
    "        'cv_accuracy': cv_results['mean_accuracy'],\n",
    "        'cv_std': cv_results['std_accuracy'],\n",
    "        'test_accuracy': test_results['accuracy']\n",
    "    }\n",
    "    \n",
    "    print(f\"   {alg.upper()} - CV: {cv_results['mean_accuracy']:.3f}¬±{cv_results['std_accuracy']:.3f}, Test: {test_results['accuracy']:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6a39c14e70f246",
   "metadata": {},
   "source": [
    "### 5.3 Results Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b4ea9ca06797f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot algorithm comparison\n",
    "algorithms = list(comparison_results.keys())\n",
    "cv_means = [comparison_results[alg]['cv_accuracy'] for alg in algorithms]\n",
    "cv_stds = [comparison_results[alg]['cv_std'] for alg in algorithms]\n",
    "test_accs = [comparison_results[alg]['test_accuracy'] for alg in algorithms]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Cross-validation results\n",
    "axes[0].bar(algorithms, cv_means, yerr=cv_stds, capsize=5, alpha=0.7)\n",
    "axes[0].set_title('Cross-Validation Accuracy')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].set_ylim(0, 1)\n",
    "for i, (mean, std) in enumerate(zip(cv_means, cv_stds)):\n",
    "    axes[0].text(i, mean + std + 0.02, f'{mean:.3f}¬±{std:.3f}', \n",
    "                ha='center', va='bottom')\n",
    "\n",
    "# Test accuracy\n",
    "bars = axes[1].bar(algorithms, test_accs, alpha=0.7)\n",
    "axes[1].set_title('Test Accuracy')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].set_ylim(0, 1)\n",
    "for i, acc in enumerate(test_accs):\n",
    "    axes[1].text(i, acc + 0.02, f'{acc:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# Highlight best algorithm\n",
    "best_alg_idx = np.argmax(cv_means)\n",
    "bars[best_alg_idx].set_color('gold')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Print best algorithm\n",
    "best_alg = algorithms[best_alg_idx]\n",
    "print(f\" Best Algorithm: {best_alg.upper()} (CV: {cv_means[best_alg_idx]:.3f}¬±{cv_stds[best_alg_idx]:.3f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e34296b8c10941",
   "metadata": {},
   "source": [
    "### 5.4 Feature Method Comparison\n",
    "\n",
    "Let's compare different feature extraction methods:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5428b01c781e3933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare feature methods using the best classifier\n",
    "print(\"Comparing feature extraction methods...\")\n",
    "\n",
    "best_classifier_alg = algorithms[np.argmax(cv_means)]\n",
    "feature_results = {}\n",
    "\n",
    "# CSP features (already computed)\n",
    "feature_results['CSP'] = {\n",
    "    'X_train': X_train_csp,\n",
    "    'X_test': X_test_csp,\n",
    "    'accuracy': comparison_results[best_classifier_alg]['test_accuracy']\n",
    "}\n",
    "\n",
    "# PSD features\n",
    "classifier_psd = BCIClassifier(algorithm=best_classifier_alg, random_state=42)\n",
    "classifier_psd.fit(X_train_psd, y_train)\n",
    "results_psd = classifier_psd.evaluate(X_test_psd, y_test)\n",
    "feature_results['PSD'] = {\n",
    "    'X_train': X_train_psd,\n",
    "    'X_test': X_test_psd,\n",
    "    'accuracy': results_psd['accuracy']\n",
    "}\n",
    "\n",
    "# Time-domain features\n",
    "classifier_time = BCIClassifier(algorithm=best_classifier_alg, random_state=42)\n",
    "classifier_time.fit(X_train_time, y_train)\n",
    "results_time = classifier_time.evaluate(X_test_time, y_test)\n",
    "feature_results['Time-domain'] = {\n",
    "    'X_train': X_train_time,\n",
    "    'X_test': X_test_time,\n",
    "    'accuracy': results_time['accuracy']\n",
    "}\n",
    "\n",
    "# Combined features\n",
    "combined_extractor = FeatureExtractor(method='combined', n_components=6)\n",
    "X_train_combined = combined_extractor.fit_transform(epochs_train, y_train)\n",
    "X_test_combined = combined_extractor.transform(epochs_test, y_test)\n",
    "\n",
    "classifier_combined = BCIClassifier(algorithm=best_classifier_alg, random_state=42)\n",
    "classifier_combined.fit(X_train_combined, y_train)\n",
    "results_combined = classifier_combined.evaluate(X_test_combined, y_test)\n",
    "feature_results['Combined'] = {\n",
    "    'X_train': X_train_combined,\n",
    "    'X_test': X_test_combined,\n",
    "    'accuracy': results_combined['accuracy']\n",
    "}\n",
    "\n",
    "# Plot feature method comparison\n",
    "feature_methods = list(feature_results.keys())\n",
    "feature_accuracies = [feature_results[method]['accuracy'] for method in feature_methods]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(feature_methods, feature_accuracies, alpha=0.7)\n",
    "plt.title(f'Feature Method Comparison ({best_classifier_alg.upper()} Classifier)')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "# Add accuracy labels\n",
    "for i, acc in enumerate(feature_accuracies):\n",
    "    plt.text(i, acc + 0.02, f'{acc:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# Highlight best method\n",
    "best_feature_idx = np.argmax(feature_accuracies)\n",
    "bars[best_feature_idx].set_color('gold')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "print(f\"üèÜ Best Feature Method: {feature_methods[best_feature_idx]} (Accuracy: {feature_accuracies[best_feature_idx]:.3f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fdf2cb20f6ba96",
   "metadata": {},
   "source": [
    "##  6. Complete Pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18655c5a50748b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize complete pipeline\n",
    "print(\"Running complete BCI classification pipeline...\")\n",
    "\n",
    "pipeline = BCIPipeline(\n",
    "    dataset='eegbci',\n",
    "    feature_method='csp',\n",
    "    classifier_algorithm='svm',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Run complete pipeline\n",
    "pipeline_results = pipeline.run_complete_pipeline(\n",
    "    subject=SUBJECT,\n",
    "    runs=RUNS,\n",
    "    tmin=TMIN,\n",
    "    tmax=TMAX,\n",
    "    l_freq=L_FREQ,\n",
    "    h_freq=H_FREQ,\n",
    "    test_size=0.2,\n",
    "    apply_ica=False,  # Set to True for better results (but slower)\n",
    "    normalize_features=True\n",
    ")\n",
    "\n",
    "print(f\" Pipeline Results:\")\n",
    "print(f\"   Test Accuracy: {pipeline_results['test_accuracy']:.3f}\")\n",
    "print(f\"   CV Accuracy: {pipeline_results['cv_mean_accuracy']:.3f} ¬± {pipeline_results['cv_std_accuracy']:.3f}\")\n",
    "\n",
    "# Get pipeline summary\n",
    "summary = pipeline.get_pipeline_summary()\n",
    "print(f\"\\n Pipeline Configuration:\")\n",
    "config = summary['configuration']\n",
    "for key, value in config.items():\n",
    "    print(f\"   {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c46a0feb99c5cd7",
   "metadata": {},
   "source": [
    "## 7. Final Results Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cca73909ebbf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive results summary\n",
    "print(\" FINAL RESULTS SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Individual component results\n",
    "print(f\"\\nBest Individual Results:\")\n",
    "print(f\"   Algorithm: {best_alg.upper()} (CV: {cv_means[best_alg_idx]:.3f}¬±{cv_stds[best_alg_idx]:.3f})\")\n",
    "print(f\"   Feature Method: {feature_methods[best_feature_idx]} (Test: {feature_accuracies[best_feature_idx]:.3f})\")\n",
    "\n",
    "# Complete pipeline results\n",
    "print(f\"\\nComplete Pipeline Results:\")\n",
    "print(f\"   Test Accuracy: {pipeline_results['test_accuracy']:.3f}\")\n",
    "print(f\"   CV Accuracy: {pipeline_results['cv_mean_accuracy']:.3f} ¬± {pipeline_results['cv_std_accuracy']:.3f}\")\n",
    "\n",
    "# Dataset information\n",
    "print(f\"\\nDataset Information:\")\n",
    "print(f\"   Subject: {SUBJECT}\")\n",
    "print(f\"   Runs: {RUNS}\")\n",
    "print(f\"   Total epochs: {len(epochs_processed)}\")\n",
    "print(f\"   Features: {X_train_csp.shape[1]} (CSP)\")\n",
    "print(f\"   Classes: {len(event_id)} ({', '.join(event_id.keys())})\")\n",
    "\n",
    "# Create final visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Algorithm comparison\n",
    "axes[0, 0].bar(algorithms, cv_means, alpha=0.7)\n",
    "axes[0, 0].set_title('Algorithm Comparison (CV Accuracy)')\n",
    "axes[0, 0].set_ylabel('Accuracy')\n",
    "for i, mean in enumerate(cv_means):\n",
    "    axes[0, 0].text(i, mean + 0.01, f'{mean:.3f}', ha='center')\n",
    "\n",
    "# Feature method comparison\n",
    "axes[0, 1].bar(feature_methods, feature_accuracies, alpha=0.7)\n",
    "axes[0, 1].set_title('Feature Method Comparison')\n",
    "axes[0, 1].set_ylabel('Test Accuracy')\n",
    "for i, acc in enumerate(feature_accuracies):\n",
    "    axes[0, 1].text(i, acc + 0.01, f'{acc:.3f}', ha='center')\n",
    "\n",
    "# Confusion matrix for best model\n",
    "best_features = feature_results[feature_methods[best_feature_idx]]\n",
    "best_classifier = BCIClassifier(algorithm=best_alg, random_state=42)\n",
    "best_classifier.fit(best_features['X_train'], y_train)\n",
    "best_results = best_classifier.evaluate(best_features['X_test'], y_test)\n",
    "\n",
    "cm = best_results['confusion_matrix']\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[1, 0],\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "axes[1, 0].set_title(f'Best Model Confusion Matrix\\n({best_alg.upper()} + {feature_methods[best_feature_idx]})')\n",
    "axes[1, 0].set_xlabel('Predicted')\n",
    "axes[1, 0].set_ylabel('Actual')\n",
    "\n",
    "# Performance timeline\n",
    "performance_data = {\n",
    "    'CSP+SVM': results_svm['accuracy'],\n",
    "    'Best Algorithm': cv_means[best_alg_idx],\n",
    "    'Best Features': feature_accuracies[best_feature_idx],\n",
    "    'Complete Pipeline': pipeline_results['test_accuracy']\n",
    "}\n",
    "\n",
    "methods = list(performance_data.keys())\n",
    "accuracies = list(performance_data.values())\n",
    "colors = ['skyblue', 'lightcoral', 'lightgreen', 'gold']\n",
    "\n",
    "axes[1, 1].bar(methods, accuracies, color=colors, alpha=0.7)\n",
    "axes[1, 1].set_title('Performance Progression')\n",
    "axes[1, 1].set_ylabel('Accuracy')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "for i, acc in enumerate(accuracies):\n",
    "    axes[1, 1].text(i, acc + 0.01, f'{acc:.3f}', ha='center')\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59195fa0c46b8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best pipeline for future use\n",
    "pipeline_path = \"best_bci_pipeline.pkl\"\n",
    "pipeline.save_pipeline(pipeline_path)\n",
    "print(f\" Best pipeline saved to: {pipeline_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
